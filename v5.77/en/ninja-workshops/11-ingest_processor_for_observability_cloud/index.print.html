<!doctype html><html lang=en dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=print><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=generator content="Relearn 7.2.1"><meta name=description content="Scenario Description"><meta name=author content><meta name=twitter:card content="summary"><meta name=twitter:title content="Ingest Processor for Splunk Observability Cloud :: Splunk Observability Cloud Workshops"><meta name=twitter:description content="Scenario Description"><meta property="og:url" content="https://splunk.github.io/observability-workshop/v5.77/en/ninja-workshops/11-ingest_processor_for_observability_cloud/index.html"><meta property="og:site_name" content="Splunk Observability Cloud Workshops"><meta property="og:title" content="Ingest Processor for Splunk Observability Cloud :: Splunk Observability Cloud Workshops"><meta property="og:description" content="Scenario Description"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta itemprop=name content="Ingest Processor for Splunk Observability Cloud :: Splunk Observability Cloud Workshops"><meta itemprop=description content="Scenario Description"><meta itemprop=dateModified content="2025-01-29T17:32:54-05:00"><meta itemprop=wordCount content="348"><title>Ingest Processor for Splunk Observability Cloud :: Splunk Observability Cloud Workshops</title>
<link href=https://splunk.github.io/observability-workshop/v5.77/en/ninja-workshops/11-ingest_processor_for_observability_cloud/index.html rel=canonical type=text/html title="Ingest Processor for Splunk Observability Cloud :: Splunk Observability Cloud Workshops"><link href=/observability-workshop/v5.77/images/favicon.ico?1738252789 rel=icon type=image/x-icon sizes=any><link href=/observability-workshop/v5.77/css/fontawesome-all.min.css?1738252789 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/observability-workshop/v5.77/css/fontawesome-all.min.css?1738252789 rel=stylesheet></noscript><link href=/observability-workshop/v5.77/css/auto-complete.css?1738252789 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/observability-workshop/v5.77/css/auto-complete.css?1738252789 rel=stylesheet></noscript><link href=/observability-workshop/v5.77/css/perfect-scrollbar.min.css?1738252789 rel=stylesheet><link href=/observability-workshop/v5.77/css/theme.min.css?1738252789 rel=stylesheet><link href=/observability-workshop/v5.77/css/format-print.min.css?1738252789 rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.relBasePath="../../..",window.relearn.relBaseUri="../../../../..",window.relearn.absBaseUri="https://splunk.github.io/observability-workshop/v5.77",window.relearn.min=`.min`,window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.relearn.themevariants=["auto","splunk-light","splunk-dark"],window.relearn.customvariantname="my-custom-variant",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}}))},window.relearn.markVariant=function(){var t=window.localStorage.getItem(window.relearn.absBaseUri+"/variant"),e=document.querySelector("#R-select-variant");e&&(e.value=t)},window.relearn.initVariant=function(){var e=window.localStorage.getItem(window.relearn.absBaseUri+"/variant")??"";e==window.relearn.customvariantname||(!e||!window.relearn.themevariants.includes(e))&&(e=window.relearn.themevariants[0],window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant(),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js crossorigin=anonymous></script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web-session-recorder.js crossorigin=anonymous></script><script>SplunkRum.init({realm:"us1",rumAccessToken:"dp3FKraOS_wVhe-l7eCOsA",applicationName:"observability-workshop",deploymentEnvironment:"splunk.github.io",version:"1.0"}),SplunkSessionRecorder.init({app:"observability-workshop",realm:"us1",rumAccessToken:"dp3FKraOS_wVhe-l7eCOsA"})</script></script><style>:root{--MAIN-WIDTH-MAX:130rem;--MENU-WIDTH-L:23rem}</style></head><body class="mobile-support print disableInlineCopyToClipboard" data-url=/observability-workshop/v5.77/en/ninja-workshops/11-ingest_processor_for_observability_cloud/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div><div class="topbar-button topbar-button-toc" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title="Table of Contents (CTRL+ALT+t)"><i class="fa-fw fas fa-list-alt"></i></button><div class=topbar-content><div class=topbar-content-wrapper></div></div></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/v5.77/en/index.html><span itemprop=name>Splunk Observability Workshops</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/v5.77/en/ninja-workshops/index.html><span itemprop=name>Ninja Workshops</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Ingest Processor for Splunk Observability Cloud</span><meta itemprop=position content="3"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.77/en/ninja-workshops/11-ingest_processor_for_observability_cloud/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></div><div class="topbar-button topbar-button-prev" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.77/en/ninja-workshops/6-lambda-kinesis/7-summary/index.html title="Conclusion (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a></div><div class="topbar-button topbar-button-next" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.77/en/ninja-workshops/11-ingest_processor_for_observability_cloud/1-getting-started/index.html title="Getting Started (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable ninja-workshops" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=ingest-processor-for-splunk-observability-cloud>Ingest Processor for Splunk Observability Cloud</h1><span class="badge cstyle blue badge-with-title"><span class=badge-title class=text-muted>Author
</span><span class=badge-content>Tim Hard</span></span><p>As infrastructure and application environments become exceedingly complex, the volume of data they generate continues to grow significantly. This increase in data volume and variety makes it challenging to gain actionable insights and can impact problem identification and troubleshooting efficiencies. Additionally, the cost of storing and accessing this data can skyrocket. Many data sources, particularly logs and events, provide critical visibility into system operations. However, in most cases, only a few details from these extensive logs are actually needed for effective monitoring and alerting.</p><p><strong>Common Challenges:</strong></p><ul><li>Increasing complexity of infrastructure and application environments.</li><li>Significant growth in data volume generated by these environments.</li><li>Challenges in gaining actionable insights from large volumes of data.</li><li>High costs associated with storing and accessing extensive data.</li><li>Logs and events provide critical visibility but often contain only a few essential details.</li></ul><p>To address these challenges, Splunk Ingest Processor provides a powerful new feature: the ability to convert log events into metrics. Metrics are more efficient to store and process, allowing for faster identification of issues, thereby reducing Mean Time to Detection (MTTD). When retaining the original log or event is necessary, they can be stored in cheaper storage solutions such as S3, reducing the overall cost of data ingestion and computation required for searching them.</p><p><strong>Solution:</strong></p><ul><li>Convert log events into metrics where possible.</li><li>Retain original logs or events in cheaper storage solutions if needed.</li><li>Utilize federated search for accessing and analyzing retained logs.</li></ul><p><strong>Outcomes:</strong></p><ul><li>Metrics are more efficient to store and process.</li><li>Faster identification of problems, reducing Mean Time to Detection (MTTD).</li><li>Lower overall data ingestion and computation costs.</li><li>Enhanced monitoring efficiency and resource optimization.</li><li>Maintain high visibility into system operations with reduced operational costs.</li></ul><p>In this workshop you&rsquo;ll have the opportunity to get hands on with Ingest Processor and Splunk Observability Cloud to see how it can be used to address the challenges outlined above and .</p><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Tip</summary><div class=box-content><p>The easiest way to navigate through this workshop is by using:</p><ul><li>the left/right arrows (<strong>&lt;</strong> | <strong>></strong>) on the top right of this page</li><li>the left (◀️) and right (▶️) cursor keys on your keyboard</li></ul></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of Ingest Processor for Splunk Observability Cloud</h1><article class=default><header class=headline></header><h1 id=getting-started>Getting Started</h1><p>During this <em><strong>technical</strong></em> Ingest Processor<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> for Splunk Observability Cloud workshop you will have the opportunity to get hands-on with Ingest Processor in Splunk Enterprise Cloud.</p><p>To simplify the workshop modules, a pre-configured Splunk Enterprise Cloud instance is provided.</p><p>The instance is pre-configured with all of the requirements for creating an Ingest Processor pipeline.</p><p>This workshop will introduce you to the benefits of using Ingest Processor to convert robust logs to metrics and send those metrics to Splunk Observability Cloud. By the end of these technical workshops, you will have a good understanding of some of the key features and capabilities of Ingest Processor in Splunk Enterprise Cloud and the value of using Splunk Observability Cloud as a destination within an Ingest Processor pipeline.</p><p>Here are the instructions on how to access your pre-configured <a href=/observability-workshop/v5.77/en/ninja-workshops/11-ingest_processor_for_observability_cloud/1-getting-started/1-access-cloud-instances/index.html>Splunk Enterprise Cloud</a> instance.</p><p><a href=#R-image-17bde4a30987d104c263f4cb9a4fbfaa class=lightbox-link><img alt="Splunk Ingest Processor Architecture" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/IngestProcessor-architecture-diagram_release_updated2.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-17bde4a30987d104c263f4cb9a4fbfaa><img alt="Splunk Ingest Processor Architecture" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/IngestProcessor-architecture-diagram_release_updated2.png></a></p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://docs.splunk.com/Documentation/SplunkCloud/9.3.2408/IngestProcessor/AboutIngestProcessorSolution rel=external target=_blank><strong>Ingest Processor</strong></a> is a data processing capability that works within your Splunk Cloud Platform deployment. Use the Ingest Processor to configure data flows, control data format, apply transformation rules prior to indexing, and route to destinations.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of 1. Getting Started</h1><article class=default><header class=headline></header><h1 id=how-to-connect-to-your-workshop-environment>How to connect to your workshop environment</h1><ol><li>How to retrieve the URL for your Splunk Enterprise Cloud instances.</li><li>How to access the Splunk Observability Cloud workshop organization.</li></ol><hr><h2 id=1-splunk-cloud-instances>1. Splunk Cloud Instances</h2><p>There are three instances that will be used throughout this workshop which have already been provisioned for you:</p><ol><li>Splunk Enterprise Cloud</li><li>Splunk Ingest Processor (SCS Tenant)</li><li>Splunk Observability Cloud</li></ol><p>The Splunk Enterprise Cloud and Ingest Processor instances are hosted in <a href=https://show.splunk.com rel=external target=_blank>Splunk Show</a>. If you were invited to the workshop, you should have received an email with an invite to the event in <a href=https://show.splunk.com rel=external target=_blank>Splunk Show</a> or a link to the event will have been provided at the beginning of the workshop.</p><p>Login to Splunk Show using your <a href=https://login.splunk.com/ rel=external target=_blank>splunk.com</a> credentials. You should see the event for this workshop. Open the event to see the instance details for your Splunk Cloud and Ingest Processor instances.</p><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p>Take note of the Participant Number provided in your Splunk Show event details. This number will be included in the <code>sourcetype</code> that you will use for searching and filtering the Kubernetes data. Because this is a shared environment only use the participant number provided so that other participants data is not effected.</p></div></details><h2 id=2-splunk-observability-cloud-instances>2. Splunk Observability Cloud Instances</h2><p>You should have also received an email to access the Splunk Observability Cloud workshop organization (You may need to check your spam folder). If you have not received an email, let your workshop instructor know. To access the environment click the <strong>Join Now</strong> button.</p><p><a href=#R-image-912edc888ae2865f049f4931eb8565bf class=lightbox-link><img alt="Splunk Observability Cloud Invitation" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/workshop_invitation.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-912edc888ae2865f049f4931eb8565bf><img alt="Splunk Observability Cloud Invitation" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/workshop_invitation.png></a></p><details open class="box cstyle notices info"><summary class=box-label><i class="fa-fw fas fa-info-circle"></i>
Important</summary><div class=box-content><p>If you access the event before the workshop start time, your instances may not be available yet. Don&rsquo;t worry, they will provided once the workshop begins.</p></div></details><p>Additionally, you have been invited to a Splunk Observability Cloud workshop organization. The invitation includes a link to the environment. If you don&rsquo;t have a Splunk Observability Cloud account already, you will be asked to create one. If you already have one, you can login to the instance and you will see the workshop organization in your available organizations.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article></section><article class=default><header class=headline></header><h1 id=how-ingest-processor-works>How Ingest Processor Works</h1><h6 id=system-architecture>System architecture</h6><p>The primary components of the Ingest Processor service include the Ingest Processor service and SPL2 pipelines that support data processing. The following diagram provides an overview of how the components of the Ingest Processor solution work together:</p><p><a href=#R-image-791ef31d342adce24844ab5c813bd8ac class=lightbox-link><img alt="Splunk Ingest Processor Architecture" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/IngestProcessor-architecture-diagram_release_updated2.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-791ef31d342adce24844ab5c813bd8ac><img alt="Splunk Ingest Processor Architecture" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/IngestProcessor-architecture-diagram_release_updated2.png></a></p><h6 id=ingest-processor-service>Ingest Processor service</h6><p>The Ingest Processor service is a cloud service hosted by Splunk. It is part of the data management experience, which is a set of services that fulfill a variety of data ingest and processing use cases.</p><p>You can use the Ingest Processor service to do the following:</p><ul><li>Create and apply SPL2 pipelines that determine how each Ingest Processor processes and routes the data that it receives.</li><li>Define source types to identify the kind of data that you want to process and determine how the Ingest Processor breaks and merges that data into distinct events.</li><li>Create connections to the destinations that you want your Ingest Processor to send processed data to.</li></ul><h6 id=pipelines>Pipelines</h6><p>A pipeline is a set of data processing instructions written in SPL2. When you create a pipeline, you write a specialized SPL2 statement that specifies which data to process, how to process it, and where to send the results. When you apply a pipeline, the Ingest Processor uses those instructions to process all the data that it receives from data sources such as Splunk forwarders, HTTP clients, and logging agents.</p><p>Each pipeline selects and works with a subset of all the data that the Ingest Processor receives. For example, you can create a pipeline that selects events with the source type <code>cisco_syslog</code> from the incoming data, and then sends them to a specified index in Splunk Cloud Platform. This subset of selected data is called a partition. For more information, see <a href=http://docs.splunk.com/Documentation/SplunkCloud/latest/IngestProcessor/Architecture#Partitions rel=external target=_blank>Partitions</a>.</p><p>The Ingest Processor solution supports only the commands and functions that are part of the <code>IngestProcessor</code> profile. For information about the specific SPL2 commands and functions that you can use to write pipelines for Ingest Processor, see <a href=http://docs.splunk.com/Documentation/SplunkCloud/latest/IngestProcessor/PipelinesOverview rel=external target=_blank>Ingest Processor pipeline syntax</a>. For a summary of how the <code>IngestProcessor</code> profile supports different commands and functions compared to other SPL2 profiles, see the following pages in the <em>SPL2 Search Reference</em>:</p><ul><li><a href=http://docs.splunk.com/Documentation/SCS/current/SearchReference/CompatibilityQuickReferenceforSPL2commands rel=external target=_blank>Compatibility Quick Reference for SPL2 commands</a></li><li><a href=http://docs.splunk.com/Documentation/SCS/current/SearchReference/CompatibilityQuickReferenceforSPL2evaluationfunctions rel=external target=_blank>Compatibility Quick Reference for SPL2 evaluation functions</a></li></ul><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=create-an-ingest-pipeline>Create an Ingest Pipeline</h1><h2 id=scenario-overview>Scenario Overview</h2><p>In this scenario you will be playing the role of a Splunk Admin responsible for managing your organizations Splunk Enterprise Cloud environment. You recently worked with an internal application team on instrumenting their Kubernetes environment with Splunk APM and Infrastructure monitoring using OpenTelemetry to monitor their critical microservice applications.</p><p>The logs from the Kubernetes environment are also being collected and sent to Splunk Enter Prize Cloud. These logs include:</p><ul><li>Pod logs (application logs)</li><li>Kubernetes Events</li><li>Kubernetes Cluster Logs<ul><li>Control Plane Node logs</li><li>Worker Node logs</li><li>Audit Logs</li></ul></li></ul><p>As a Splunk Admin you want to ensure that the data you are collecting is optimized so it can be analyzed in the most efficient way possible. Taking this approach accelerates troubleshooting and ensures efficient license utilization.</p><p>One way to accomplish this is by using Ingest Processor to convert robust logs to metrics and use Splunk Observability Cloud as the destination for those metrics. Not only does this make collecting the logs more efficient, you have the added ability of using the newly created metrics in Splunk Observability which can then be correlated with Splunk APM data (traces) and Splunk Infrastructure Monitoring data providing additional troubleshooting context. Because Splunk Observability Cloud uses a streaming metrics pipeline, the metrics can be alerted on in real-time speeding up problem identification. Additionally, you can use the Metrics Pipeline Management functionality to further optimize the data by aggregating, dropping unnecessary fields, and archiving less important or un-needed metrics.</p><p>In the next step you&rsquo;ll create an Ingest Processor Pipeline which will convert Kubernetes Audit Logs to metrics that will be sent to Observability Cloud.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of 3. Create an Ingest Pipeline</h1><article class=default><header class=headline></header><h1 id=login-to-splunk-cloud>Login to Splunk Cloud</h1><p>In this section you will create an Ingest Pipeline which will convert Kubernetes Audit Logs to metrics which are sent to the Splunk Observability Cloud workshop organization. Before getting started you will need to access the Splunk Cloud and Ingest Processor SCS Tenant environments provided in the Splunk Show event details.</p><details open class="box cstyle notices green"><summary class=box-label><i class="fa-fw fas fa-running"></i>
Pre-requisite: Login to Splunk Enterprise Cloud</summary><div class=box-content><p>Open the <strong>Ingest Processor Cloud Stack</strong> URL provided in the Splunk Show event details.</p><p><a href=#R-image-a30e8938f3c7a3c61dd034b9d8cac29b class=lightbox-link><img alt="Splunk Cloud Instance Details" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/show_instances_sec.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-a30e8938f3c7a3c61dd034b9d8cac29b><img alt="Splunk Cloud Instance Details" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/show_instances_sec.png></a></p><p>In the Connection info click on the <strong>Stack URL</strong> link to open your Splunk Cloud stack.</p><p><a href=#R-image-65cd69f15dec5d1c368f455db00d2e0f class=lightbox-link><img alt="Splunk Cloud Connection Details" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/sec_connection_details.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-65cd69f15dec5d1c368f455db00d2e0f><img alt="Splunk Cloud Connection Details" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/sec_connection_details.png></a></p><p>Use the <code>admin</code> username and password to login to Splunk Cloud.</p><p><a href=#R-image-2c716e9c8aa8e5b36564485ebc1d7c36 class=lightbox-link><img alt="Splunk Cloud Login" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/sec_login.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-2c716e9c8aa8e5b36564485ebc1d7c36><img alt="Splunk Cloud Login" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/sec_login.png></a></p><p>After logging in, if prompted, accept the Terms of Service and click <strong>OK</strong></p><p><a href=#R-image-caeedb6a05b2551d71c53f81f9a2fddc class=lightbox-link><img alt="Splunk Cloud Login" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/sec_terms.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-caeedb6a05b2551d71c53f81f9a2fddc><img alt="Splunk Cloud Login" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/sec_terms.png></a></p><p>Navigate back to the Splunk Show event details and select the Ingest Processor SCS Tenant</p><p><a href=#R-image-6cedf98d72444c9fc16f40b5b566866a class=lightbox-link><img alt="Ingest Processor Connection Details" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/show_instances_scs.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-6cedf98d72444c9fc16f40b5b566866a><img alt="Ingest Processor Connection Details" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/show_instances_scs.png></a></p><p>Click on the <strong>Console URL</strong> to access the <strong>Ingest Processor SCS Tenant</strong></p><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p><strong>Single Sign-On (SSO)</strong>
Single Sign-on (SSO) is configured between the Splunk Data Management service (‘SCS Tenant’) and Splunk Cloud environments, so if you already logged in to your Splunk Cloud stack you should automatically be logged in to Splunk Data Management service. If you are prompted for credentials, use the credentials provided in the Splunk Cloud Stack on Splunk Show event (listed under the ‘Splunk Cloud Stack’ section.)</p></div></details></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=review-kubernetes-audit-logs>Review Kubernetes Audit Logs</h1><p>In this section you will review the Kubernetes Audit Logs that are being collected. You can see that the events are quite robust, which can make charting them inefficient. To address this, you will create an Ingest Pipeline in Ingest Processor that will convert these events to metrics that will be sent to Splunk Observability Cloud. This will allow you to chart the events much more efficiently and take advantage of the real-time streaming metrics in Splunk Observability Cloud.</p><details open class="box cstyle notices green"><summary class=box-label><i class="fa-fw fas fa-running"></i>
Exercise: Create Ingest Pipeline</summary><div class=box-content><ol><li><p>Open your <strong>Ingest Processor Cloud Stack</strong> instance using the URL provided in the Splunk Show workshop details.</p></li><li><p>Navigate to <strong>Apps</strong> -> <strong>Search and Reporting</strong></p></li></ol><p><a href=#R-image-e5057f742f89867a6563e3e2816ede86 class=lightbox-link><img alt="Search and Reporting" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/search_and_reporting.png?width=20vw" style=height:auto;width:20vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-e5057f742f89867a6563e3e2816ede86><img alt="Search and Reporting" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/search_and_reporting.png?width=20vw"></a></p><ol start=3><li>In the search bar, enter the following SPL search string:</li></ol><div class="highlight wrap-code"><pre tabindex=0><code>```Replace PARTICIPANT_NUMBER with the participant number provided in your Splunk Show event details```
index=main sourcetype=&#34;kube:apiserver:audit:PARTICIPANT_NUMBER&#34;</code></pre></div><ol start=4><li>Press <strong>Enter</strong> or click the green magnifying glass to run the search.</li></ol><p><a href=#R-image-b743236f93522bddeb7aed65442e718b class=lightbox-link><img alt="Kubernetes Audit Log" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/k8s_audit_log.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-b743236f93522bddeb7aed65442e718b><img alt="Kubernetes Audit Log" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/k8s_audit_log.png></a></p><p>You should now see the Kubernetes Audit Logs for your environment. Notice that the events are fairly robust. Explore the available fields and start to think about what information would be good candidates for metrics and dimensions. Ask yourself: What fields would I like to chart and how would I like to be able to filter, group, or split those fields?</p></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=create-an-ingest-pipeline>Create an Ingest Pipeline</h1><p>In this section you will create an Ingest Pipeline which will convert Kubernetes Audit Logs to metrics which are sent to the Splunk Observability Cloud workshop organization.</p><details open class="box cstyle notices green"><summary class=box-label><i class="fa-fw fas fa-running"></i>
Exercise: Create Ingest Pipeline</summary><div class=box-content><ol><li>Open the <strong>Ingest Processor SCS Tenant</strong> using the connection details provided in the Splunk Show event.</li></ol><p><a href=#R-image-bedde60f18a9f551ef5ddd3fb7e54412 class=lightbox-link><img alt="Launch Splunk Cloud Platform" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/data_management_home.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-bedde60f18a9f551ef5ddd3fb7e54412><img alt="Launch Splunk Cloud Platform" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/data_management_home.png?width=40vw"></a></p><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p>When you open the <strong>Ingest Processor SCS Tenant</strong>, if you are taken to a welcome page, click on <strong>Launch</strong> under <strong>Splunk Cloud Platform</strong> to be taken the the Data Management page where you will configure the Ingest Pipeline.</p><p><a href=#R-image-2387df954747691af30709a1ba968be7 class=lightbox-link><img alt="Launch Splunk Cloud Platform" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/launch_scp.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-2387df954747691af30709a1ba968be7><img alt="Launch Splunk Cloud Platform" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/launch_scp.png></a></p></div></details><ol start=2><li>From the Splunk Data Management console select <strong>Pipelines</strong> -> <strong>New pipeline</strong> -> <strong>Ingest Processor pipeline</strong>.</li></ol><p><a href=#R-image-287518fc5ddbee544b9b8079d3b1e2b7 class=lightbox-link><img alt="New Ingest Processor Pipeline" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/new_pipeline.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-287518fc5ddbee544b9b8079d3b1e2b7><img alt="New Ingest Processor Pipeline" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/new_pipeline.png?width=40vw"></a></p><ol start=3><li>In the <strong>Get started</strong> step of the Ingest Processor configuration page select <strong>Blank Pipeline</strong> and click <strong>Next</strong>.</li></ol><p><a href=#R-image-58f73a49dd51049a655f21296558a1a3 class=lightbox-link><img alt="Blank Ingest Processor Pipeline" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/blank_pipeline.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-58f73a49dd51049a655f21296558a1a3><img alt="Blank Ingest Processor Pipeline" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/blank_pipeline.png?width=40vw"></a></p><ol start=4><li>In the <strong>Define your pipeline’s partition</strong> step of the Ingest Processor configuration page select <strong>Partition by sourcetype</strong>. Select the <strong>= equals</strong> Operator and enter <code>kube:apiserver:audit:PARTICIPANT_NUMBER</code> (Be sure to replace PARTICIPANT_NUMBER with the participant number you were assigned) for the value. Click <strong>Apply</strong>.</li></ol><p><a href=#R-image-747f68b07d9d8d399f8c5a16d9cc8889 class=lightbox-link><img alt="Add Partition" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/add_partition.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-747f68b07d9d8d399f8c5a16d9cc8889><img alt="Add Partition" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/add_partition.png?width=40vw"></a></p><ol start=5><li><p>Click <strong>Next</strong></p></li><li><p>In the <strong>Add sample data</strong> step of the Ingest Processor configuration page select <strong>Capture new snapshot</strong>. Enter <code>k8s_audit</code> for the name and click <strong>Capture</strong>.</p></li></ol><p><a href=#R-image-b5b28579526d260a9928284252be3c75 class=lightbox-link><img alt="Capture Snapshot" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/capture_snapshot.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-b5b28579526d260a9928284252be3c75><img alt="Capture Snapshot" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/capture_snapshot.png?width=40vw"></a></p><ol start=7><li>Make sure your newly created snapshot (<code>k8s_audit</code>) is selected and then click <strong>Next</strong>.</li></ol><p><a href=#R-image-aee5dc4f615454b514c8c24fc739b51f class=lightbox-link><img alt="Configure Snapshot Sourcetype" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/capture_snapshot_sourcetype.png?width=20vw" style=height:auto;width:20vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-aee5dc4f615454b514c8c24fc739b51f><img alt="Configure Snapshot Sourcetype" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/capture_snapshot_sourcetype.png?width=20vw"></a></p><ol start=8><li>In the <strong>Select a metrics destination</strong> step of the Ingest Processor configuration page select <strong>show_o11y_org</strong>. Click <strong>Next</strong>.</li></ol><p><a href=#R-image-3f6e0f0b19aed7c5073f07f6c72c9824 class=lightbox-link><img alt="Metrics Destination" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/metrics_destination.png?width=20vw" style=height:auto;width:20vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-3f6e0f0b19aed7c5073f07f6c72c9824><img alt="Metrics Destination" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/metrics_destination.png?width=20vw"></a></p><ol start=9><li>In the <strong>Select a data destination</strong> step of the Ingest Processor configuration page select <strong>splunk_indexer</strong>. Under <strong>Specify how you want your events to be routed to an index</strong> select <strong>Default</strong>. Click <strong>Done</strong>.</li></ol><p><a href=#R-image-54909f8f3badd3e7146a6af6413a640c class=lightbox-link><img alt="Event Routing" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/event_routing.png?width=20vw" style=height:auto;width:20vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-54909f8f3badd3e7146a6af6413a640c><img alt="Event Routing" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/event_routing.png?width=20vw"></a></p><ol start=10><li>In the <strong>Pipeline search field</strong> replace the default search with the following.</li></ol><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p><strong>Replace <code>UNIQUE_FIELD</code> in the metric name with a unique value which will be used to identify your metric in Observability Cloud.</strong></p></div></details><div class="highlight wrap-code"><pre tabindex=0><code>/*A valid SPL2 statement for a pipeline must start with &#34;$pipeline&#34;, and include &#34;from $source&#34; and &#34;into $destination&#34;.*/
/* Import logs_to_metrics */
import logs_to_metrics from /splunk/ingest/commands
$pipeline =
| from $source
| thru [
//define the metric name, type, and value for the Kubernetes Events
| logs_to_metrics name=&#34;k8s_audit_UNIQUE_FIELD&#34; metrictype=&#34;counter&#34; value=1 time=_time
| into $metrics_destination
]
| eval index = &#34;kube_logs&#34;
//Send unfiltered logs to S3
| into $destination;</code></pre></div><details open class="box cstyle notices info"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
New to SPL2?</summary><div class=box-content><p>Here is a breakdown of what the SPL2 query is doing:</p><ul><li>First, you are importing the built in <code>logs_to_metrics</code> command which will be used to convert the kubernetes events to metrics.</li><li>You&rsquo;re using the source data, which you can see on the right is any event from the <code>kube:apiserver:audit</code> sourcetype.</li><li>Now, you use the <code>thru</code> command which writes the source dataset to the following command, in this case <code>logs_to_metrics</code>.</li><li>You can see that the metric name (<code>k8s_audit</code>), metric type (<code>counter</code>), value, and timestamp are all provided for the metric. You’re using a value of 1 for this metric because we want to count the number of times the event occurs.</li><li>Next, you choose the destination for the metric using the into <code>$metrics_destintation</code> command, which is our Splunk Observability Cloud organization</li><li>Finally, you can send the raw log events to another destination, in this case another index, so they are retained if we ever need to access them.</li></ul></div></details><ol start=11><li>In the upper-right corner click the <strong>Preview</strong> button <a href=#R-image-96df86e825d29e2fb73347e7b1b50938 class=lightbox-link><img alt="Preview Button" class="noborder inline lazy lightbox noshadow figure-image" loading=lazy src="../../images/preview.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-96df86e825d29e2fb73347e7b1b50938><img alt="Preview Button" class="noborder inline lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/preview.png?height=20px&classes=inline"></a> or press CTRL+Enter (CMD+Enter on Mac). From the <strong>Previewing $pipeline</strong> dropdown select <strong>$metrics_destination</strong>. Confirm you are seeing a preview of the metrics that will be sent to Splunk Observability Cloud.</li></ol><p><a href=#R-image-adbb8998178b52470a85beed356b0b5d class=lightbox-link><img alt="Preview Pipeline" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/preview_pipeline.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-adbb8998178b52470a85beed356b0b5d><img alt="Preview Pipeline" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/preview_pipeline.png?width=40vw"></a></p><ol start=12><li>In the upper-right corner click the <strong>Save pipeline</strong> button <a href=#R-image-761898119bd7620560d1229c9cb8c606 class=lightbox-link><img alt="Save Pipeline Button" class="noborder inline lazy lightbox noshadow figure-image" loading=lazy src="../../images/save_pipeline_btn.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-761898119bd7620560d1229c9cb8c606><img alt="Save Pipeline Button" class="noborder inline lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/save_pipeline_btn.png?height=20px&classes=inline"></a>. Enter a name for your pipeline and click <strong>Save</strong>.</li></ol><p><a href=#R-image-145f825e96e2b15b6ad2553c56bca685 class=lightbox-link><img alt="Save Pipeline Dialog" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/save_pipeline_dialog.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-145f825e96e2b15b6ad2553c56bca685><img alt="Save Pipeline Dialog" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/save_pipeline_dialog.png?width=40vw"></a></p><ol start=13><li>After clicking save you will be asked if you would like to apply the newly created pipeline. Click <strong>Yes, apply</strong>.</li></ol><p><a href=#R-image-b57388a173e2bb996a702cc59760b570 class=lightbox-link><img alt="Apply Pipeline Dialog" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/apply_pipeline_dialog.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-b57388a173e2bb996a702cc59760b570><img alt="Apply Pipeline Dialog" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/apply_pipeline_dialog.png?width=40vw"></a></p><center><b>The Ingest Pipeline should now be sending metrics to Splunk Observability Cloud. Keep this tab open as it will be used it again in the next section.</b><p>In the next step you&rsquo;ll confirm the pipeline is working by viewing the metrics you just created in Splunk Observability Cloud.</p></center></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=confirm-metrics-in-splunk-observability-cloud>Confirm Metrics in Splunk Observability Cloud</h1><p>Now that an Ingest Pipeline has been configured to convert Kubernetes Audit Logs into metrics and send them to Splunk Observability Cloud the metrics should be available. To confirm the metrics are being collected complete the following steps:</p><details open class="box cstyle notices green"><summary class=box-label><i class="fa-fw fas fa-running"></i>
Exercise: Confirm Metrics in Splunk Observability Cloud</summary><div class=box-content><ol><li>Login to the <strong>Splunk Observability Cloud</strong> organization you were invited for the workshop. In the upper-right corner, click the <strong>+</strong> Icon -> <strong>Chart</strong> to create a new chart.</li></ol><p><a href=#R-image-4f9d932e916c6328b141d3718538f0b0 class=lightbox-link><img alt="Create New Chart" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/create_new_chart.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-4f9d932e916c6328b141d3718538f0b0><img alt="Create New Chart" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/create_new_chart.png?width=40vw"></a></p><ol start=2><li>In the <strong>Plot Editor</strong> of the newly created chart enter the metric name you used while configuring the <strong>Ingest Pipeline</strong>.</li></ol><p><a href=#R-image-b4b9d6268a677c9a15bc9b903a7a18fe class=lightbox-link><img alt="Review Metric" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/review_metric.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-b4b9d6268a677c9a15bc9b903a7a18fe><img alt="Review Metric" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/review_metric.png?width=40vw"></a></p><center><b>You should see the metric you created in the Ingest Pipeline. Keep this tab open as it will be used again in the next section.</b><p>In the next step you will update the ingest pipeline to add dimensions to the metric so you have additional context for alerting and troubleshooting.</p></center></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article></section><article class=default><header class=headline></header><h1 id=update-pipeline-and-visualize-metrics>Update Pipeline and Visualize Metrics</h1><h2 id=context-matters>Context Matters</h2><p>In the previous section, you reviewed the raw Kubernetes audit logs and created an Ingest Processor Pipeline to convert them to metrics and send those metrics to Splunk Observability Cloud.</p><p>Now that this pipeline is defined we are collecting the new metrics in Splunk Observability Cloud. This is a great start; however, you will only see a single metric showing the total number of kubernetes audit events for a given time period. It would be much more valuable to add dimensions so that you can split the metric by the event type, user, response status, and so on.</p><p>In this section you will update the Ingest Processor Pipeline to include additional dimensions from the Kubernetes audit logs to the metrics that are being collected. This will allow you to further filter, group, visualize, and alert on specific aspects of the audit logs. After updating the metric, you will create a new dashboard showing the status of the different types of actions associated with the logs.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of 4. Update Pipeline and Visualize Metrics</h1><article class=default><header class=headline></header><h1 id=update-ingest-pipeline>Update Ingest Pipeline</h1><details open class="box cstyle notices green"><summary class=box-label><i class="fa-fw fas fa-running"></i>
Exercise: Update Ingest Pipeline</summary><div class=box-content><ol><li>Navigate back to the configuration page for the Ingest Pipeline you created in the previous step.</li></ol><p><a href=#R-image-cc7a6ec69ff245d98479e3d5c12b14fb class=lightbox-link><img alt="Ingest Pipeline" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/ingest_pipeline.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-cc7a6ec69ff245d98479e3d5c12b14fb><img alt="Ingest Pipeline" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/ingest_pipeline.png?width=40vw"></a></p><ol start=2><li>To add dimensions to the metric from the raw Kubernetes audit logs update the SPL2 query you created for the pipeline by replacing the <code>logs_to_metrics</code> portion of the query with the following.</li></ol><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p><strong>Be sure to update the metric name field (<code>name="k8s_audit"</code>) to the name you provided in the original pipeline</strong></p></div></details><div class="highlight wrap-code"><pre tabindex=0><code>| logs_to_metrics name=&#34;k8s_audit&#34; metrictype=&#34;counter&#34; value=1 time=_time dimensions={&#34;level&#34;: _raw.level, &#34;response_status&#34;: _raw.responseStatus.code, &#34;namespace&#34;: _raw.objectRef.namespace, &#34;resource&#34;: _raw.objectRef.resource, &#34;user&#34;: _raw.user.username, &#34;action&#34;: _raw.verb}</code></pre></div><details open class="box cstyle notices info"><summary class=box-label><i class="fa-fw fas fa-info"></i>
Note</summary><div class=box-content><p>Using the <code>dimensions</code> field in the SPL2 query you can add dimensions from the raw events to the metrics that will be sent to Splunk Observability Cloud. In this case you are adding the event response status, namespace, kubernetes resource, user, and verb (action that was performed). These dimensions can be used to create more granular dashboards and alerts.</p><p>You should consider adding any common tags across your services so that you can take advantage of context propagation and related content in Splunk Observability Cloud.</p></div></details><ol start=3><li>In the upper-right corner click the <strong>Preview</strong> button <a href=#R-image-b1b95a825ece820591b16f1cf55fe97e class=lightbox-link><img alt="Preview Button" class="noborder inline lazy lightbox noshadow figure-image" loading=lazy src="../../images/preview.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-b1b95a825ece820591b16f1cf55fe97e><img alt="Preview Button" class="noborder inline lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/preview.png?height=20px&classes=inline"></a> or press CTRL+Enter (CMD+Enter on Mac). From the <strong>Previewing $pipeline</strong> dropdown select <strong>$metrics_destination</strong>. Confirm you are seeing a preview of the metrics that will be sent to Splunk Observability Cloud.</li></ol><p><a href=#R-image-ccce38dbda70919ec12b5715e0b922e5 class=lightbox-link><img alt="Ingest Pipeline Dimensions" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/ingest_pipeline_dimensions.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-ccce38dbda70919ec12b5715e0b922e5><img alt="Ingest Pipeline Dimensions" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/ingest_pipeline_dimensions.png?width=40vw"></a></p><ol start=4><li>Confirm you are seeing the dimensions in the dimensions column of the preview table. You can view the entire dimensions object by clicking into the table.</li></ol><p><a href=#R-image-0d1e6f42ca175da137b7c849f5847dbb class=lightbox-link><img alt="Ingest Pipeline Dimensions Review" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/ingest_pipeline_dimensions_field.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-0d1e6f42ca175da137b7c849f5847dbb><img alt="Ingest Pipeline Dimensions Review" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/ingest_pipeline_dimensions_field.png?width=40vw"></a></p><ol start=5><li>In the upper-right corner click the <strong>Save pipeline</strong> button <a href=#R-image-f00a42f8ab242cad1ebb464090df395d class=lightbox-link><img alt="Save Pipeline Button" class="noborder inline lazy lightbox noshadow figure-image" loading=lazy src="../../images/save_pipeline_btn.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-f00a42f8ab242cad1ebb464090df395d><img alt="Save Pipeline Button" class="noborder inline lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/save_pipeline_btn.png?height=20px&classes=inline"></a>. On the “You are editing an active pipeline modal” click <strong>Save</strong>.</li></ol><p><a href=#R-image-8c65596e6e3cb37cacdc2e0d479000cc class=lightbox-link><img alt="Save Updated Pipeline" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/save_updated_pipeline.png?width=30vw" style=height:auto;width:30vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-8c65596e6e3cb37cacdc2e0d479000cc><img alt="Save Updated Pipeline" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/save_updated_pipeline.png?width=30vw"></a></p><center><b>Because this pipeline is already active, the changes we’ve made will take effect immediately. Your metric should now be split into multiple metric timeseries using the dimensions you added.</b><p>In the next step you will create a visualization using different dimensions from the kubernetes audit events.</p></center></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=visualize-kubernetes-audit-event-metrics>Visualize Kubernetes Audit Event Metrics</h1><p>Now that your metric has dimensions you will create a chart showing the health of different Kubernetes actions using the <code>verb</code> dimension from the events.</p><details open class="box cstyle notices green"><summary class=box-label><i class="fa-fw fas fa-running"></i>
Exercise: Visualize Kubernetes Audit Event Metrics</summary><div class=box-content><ol><li>If you closed the chart you created in the previous section, in the upper-right corner, click the <strong>+</strong> Icon -> <strong>Chart</strong> to create a new chart.</li></ol><p><a href=#R-image-4156c323dfd24470ec365411a967feac class=lightbox-link><img alt="Create New Chart" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/create_new_chart.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-4156c323dfd24470ec365411a967feac><img alt="Create New Chart" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/create_new_chart.png?width=40vw"></a></p><ol start=2><li>In the <strong>Plot Editor</strong> of the newly created chart enter the metric name you used while configuring the <strong>Ingest Pipeline</strong>.</li></ol><p><a href=#R-image-f3a1bcd9cc3aea38d7c6b088ed327573 class=lightbox-link><img alt="Review Metric" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/review_metric.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-f3a1bcd9cc3aea38d7c6b088ed327573><img alt="Review Metric" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/review_metric.png?width=40vw"></a></p><ol start=3><li>Notice the change from one to many metrics, which is when you updated the pipeline to include the dimensions. Now that we have this metric available, let&rsquo;s adjust the chart to show us if any of our actions have errors associated with them.</li></ol><p><a href=#R-image-c1b614dbc9578f04095aa4d8cf29ce1d class=lightbox-link><img alt="Metric Timeseries" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/metric_timeseries.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-c1b614dbc9578f04095aa4d8cf29ce1d><img alt="Metric Timeseries" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/metric_timeseries.png?width=40vw"></a></p><div style=width:60vw;justify-self:center>First you'll filter the Kubernetes events to only those that were not successful using the HTTP response code which is available in the <b>response_status</b> field. We only want events that have a response code of <b>409</b>, which indicates that there was a conflict (for example a trying to create a resource that already exists) or <b>503</b>, which indicates that the API was unresponsive for the request.</div><ol start=4><li>In the plot editor of your chart click the <strong>Add filter</strong>, use <strong>response_status</strong> for the field and select <strong>409.0</strong> and <strong>503.0</strong> for the values.</li></ol><div style=width:60vw;justify-self:center>Next, you’ll add a function to the chart which will calculate the total number of events grouped by the **resource**, <b>action</b>, and <b>response status</b>. This will allow us to see exactly which actions and the associated resources had errors. Now we are only looking at kubernetes events that were not successful.</div><ol start=5><li>Click <strong>Add analytics</strong> -> <strong>Sum</strong> -> <strong>Sum:Aggregation</strong> and add <strong>resource</strong>, <strong>action</strong>, and <strong>response_status</strong> in the <strong>Group by</strong> field.</li></ol><p><a href=#R-image-396a4e2abf2034545d3ef67175e4d275 class=lightbox-link><img alt="Add Metric Filters" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/add_metric_filters.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-396a4e2abf2034545d3ef67175e4d275><img alt="Add Metric Filters" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/add_metric_filters.png?width=40vw"></a></p><ol start=6><li>Using the chart type along the top buttons, change the chart to a <strong>heatmap</strong>. Next to the <strong>Plot editor</strong>, click <strong>Chart options</strong>. In the <strong>Group by</strong> section select <strong>response_status</strong> then <strong>action</strong>. Change the <strong>Color threshold</strong> from <strong>Auto</strong> to <strong>Fixed</strong>. Click the blue <strong>+ button</strong> to add another threshold. Change the <strong>Down arrow to Yellow</strong>, the <strong>Middle to orange</strong>. Leave the <strong>Up arrow as red</strong>. Enter <strong>5 for the middle threshold</strong> and <strong>20 for the upper threshold</strong>.</li></ol><p><a href=#R-image-e165a67b9ee61c0e74a625d79fd9b9a0 class=lightbox-link><img alt="Configure Thresholds" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/configure_thresholds.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-e165a67b9ee61c0e74a625d79fd9b9a0><img alt="Configure Thresholds" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/configure_thresholds.png?width=40vw"></a></p><ol start=7><li>In the upper right corner of the chart click the blue <strong>Save as&mldr;</strong> <a href=#R-image-30b5468dc3f3c747fcc0d5fbf566f0b4 class=lightbox-link><img alt="Preview Button" class="noborder inline lazy lightbox noshadow figure-image" loading=lazy src="../../images/save_as_btn.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-30b5468dc3f3c747fcc0d5fbf566f0b4><img alt="Preview Button" class="noborder inline lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/save_as_btn.png?height=20px&classes=inline"></a> button. Enter a name for your chart (For Example: Kubernetes Audit Logs - Conflicts and Failures).</li></ol><p><a href=#R-image-c64cc78e2448e1cc775695d14cc0e9a9 class=lightbox-link><img alt="Chart Name" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/chart_name.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-c64cc78e2448e1cc775695d14cc0e9a9><img alt="Chart Name" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/chart_name.png></a></p><ol start=8><li>On the <strong>Choose a dashboard</strong> select <strong>New dashboard</strong>.</li></ol><p><a href=#R-image-80ec87f8cc434f849f361c45bf320b02 class=lightbox-link><img alt="New Dashboard" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/new_dashboard.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-80ec87f8cc434f849f361c45bf320b02><img alt="New Dashboard" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/new_dashboard.png></a></p><ol start=9><li>Enter a name for your dashboard that includes your initials so you can easily find it later. Click <strong>Save</strong>.</li></ol><p><a href=#R-image-0bee42991f50ebe8f06279584690ba80 class=lightbox-link><img alt="New Dashboard Name" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/dashboard_name.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-0bee42991f50ebe8f06279584690ba80><img alt="New Dashboard Name" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/dashboard_name.png></a></p><ol start=10><li>Make sure the new dashboard you just created is selected and click <strong>Ok</strong>.</li></ol><p><a href=#R-image-b72f295c24f8967133875362c2a5f78a class=lightbox-link><img alt="Save New Dashboard" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/save_new_dashboard.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-b72f295c24f8967133875362c2a5f78a><img alt="Save New Dashboard" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/save_new_dashboard.png></a></p><p>You should now be taken to your new Kubernetes Audit Events dashboard with the chart you created. You can add new charts from other metrics in your environment, such as application errors and response times from the applications running in the Kubernetes cluster, or other Kubernetes metrics such as pod phase, pod memory utilization, etc. giving you a correlated view of your Kubernetes environment from cluster events to application health.</p><p><a href=#R-image-9446d954e81c8c23c5a74f6daecbf5a3 class=lightbox-link><img alt="Audit Dashboard" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/audit_dashboard.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-9446d954e81c8c23c5a74f6daecbf5a3><img alt="Audit Dashboard" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/audit_dashboard.png?width=40vw"></a></p></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article></section><article class=default><header class=headline></header><h1 id=conclusion>Conclusion</h1><p>In this workshop, you walked through the entire process of optimizing Kubernetes log management by converting detailed log events into actionable metrics using <strong>Splunk Ingest Pipelines</strong>. You started by defining a pipeline that efficiently converts Kubernetes audit logs into metrics, drastically reducing the data volume while retaining critical information. You then ensured the raw log events were securely stored in S3 for long-term retention and deeper analysis.</p><p><a href=#R-image-695a004815b9ec14db13ca180cbab28b class=lightbox-link><img alt="Kubernetes Audit Event" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../images/audit_event.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-695a004815b9ec14db13ca180cbab28b><img alt="Kubernetes Audit Event" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../images/audit_event.png?width=40vw"></a></p><p>Next, you demonstrated how to enhance these metrics by adding key dimensions from the raw events, enabling us to drill down into specific actions and resources. you created a chart that filtered the metrics to focus on errors, breaking them out by resource and action. This allowed us to pinpoint exactly where issues were occurring in real-time.</p><p><a href=#R-image-73f1fafdf010b0d3156d3a0ffa32a2f6 class=lightbox-link><img alt="Ingest Pipeline" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../images/ingest_pipeline_dimensions.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-73f1fafdf010b0d3156d3a0ffa32a2f6><img alt="Ingest Pipeline" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../images/ingest_pipeline_dimensions.png?width=40vw"></a></p><p>The real-time architecture of <strong>Splunk Observability Cloud</strong> means that these metrics can trigger alerts the moment an issue is detected, significantly reducing the Mean Time to Detection (MTTD). Additionally, you showed how this chart can be easily saved to new or existing dashboards, ensuring ongoing visibility and monitoring of critical metrics.</p><p><a href=#R-image-fd0435953136c09afce701068ac3d572 class=lightbox-link><img alt="Audit Dashboard" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../images/audit_dashboard.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-fd0435953136c09afce701068ac3d572><img alt="Audit Dashboard" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../images/audit_dashboard.png?width=40vw"></a></p><p>The value behind this approach is clear: by converting logs to metrics using <strong>Ingest Processor</strong>, you not only streamline data processing and reduce storage costs but also gain the ability to monitor and respond to issues in real-time using <strong>Splunk Observability Cloud</strong>. This results in faster problem resolution, improved system reliability, and more efficient resource utilization, all while maintaining the ability to retain and access the original logs for compliance or deeper analysis.</p><center><h1>Happy Splunking!</h1></center><p><a href=#R-image-dee19aba9b626ed1e7340000d10b82d4 class=lightbox-link><img alt="Dancing Buttercup" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../images/Splunk-dancing-buttercup-GIF-103.gif?width=30vw" style=height:auto;width:30vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-dee19aba9b626ed1e7340000d10b82d4><img alt="Dancing Buttercup" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../images/Splunk-dancing-buttercup-GIF-103.gif?width=30vw"></a></p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article></section></div></main></div><script src=/observability-workshop/v5.77/js/clipboard.min.js?1738252789 defer></script><script src=/observability-workshop/v5.77/js/perfect-scrollbar.min.js?1738252789 defer></script><script src=/observability-workshop/v5.77/js/theme.js?1738252789 defer></script></body></html>